\documentclass{report}
    \usepackage[utf8]{inputenc}
    \usepackage[spanish, es-nodecimaldot]{babel}
    \usepackage{amsmath}
    \usepackage{graphics}
    \usepackage{amssymb}
    \setlength{\oddsidemargin}{0.5cm}
    \setlength{\evensidemargin}{0.5cm}
    \setlength{\textwidth}{15cm}
    \setlength{\topmargin}{-2cm}
\begin{document}
\begin{center}
    \textsf{\Large Procesos Estocásticos}
    \par\medskip
    \textsf{\large Examen Parcial 1}
    \end{center}
    \hrule
    \par\bigskip

\begin{enumerate}
    \item Supongamos que tenemos dos cajas con $2d$ bolas,  de las cuales $d$ son negras y $d$ son rojas. Inicialmente $d$ bolas son colocadas en la caja 1 y el resto en la caja 2. En cada intento, una bola es seleccionada de cada caja aleatoriamente y es cambiada de caja. Sea $X_0$ el número de bolas negras que inicialmente se encuentran en la caja 1 y $X_n$ el número de bolas negras en la caja 1 después de $n$ extracciones. Encuentra la probabilidad de transición de la cadena de Markov $\left\{X_n\right\}$.

\item Sea $\left\{X_n\right\}$ una cadena de Markov con matriz de transición:
$$P= \left[
    \begin{matrix}
        0.6 & & 0.3 & 0.1 \\
        0.3 & & 0.3 & 0.4 \\
        0.4 & & 0.1 & 0.5 \\
    \end{matrix}
    \right]
$$
Si se sabe que $X_0=1$, determina $P(X_2 = 1)$.
\item Sea $\left\{X_n\right\}_{n\geq 0}$ la cadena de dos estados con matriz de transición:
$$P= \left[
    \begin{matrix}
        1-p &  p \\
        q   &  1-q \\
    \end{matrix}
    \right]
$$
\begin{enumerate}
    \item Encuentra $P(\left. T_0=n\right\vert X_0=0)$
    \item Encuentra $P(\left. T_1=n\right\vert X_0=0)$
\end{enumerate}
\item Prueba que $\rho_{xy}>0$ si y sólo si $P^n(x,y)>0$ para algún entero positivo $n$.
\item Sea $X$ una variable aleatoria binomial con parámetros $p$ y $N$, donde $N$ es también una variable aleatoria con distribución binomial y parámetros $q$ y $M$. Encuentra la distribución marginal de $X$.
\item Supongamos que $X$ es una variable aleatoria que se distribuye binomial con parámetros $p$ y $N$, donde $N$ tiene distribución Poisson con media $\lambda$. Encuentra la distribución marginal de $X$. 
\item La cadena de Markov $\{X_n\}$, con espacio de estados, $S =\{0,1,2\}$ tiene matriz de transición:
$$
P = \left(\begin{matrix}
	0 .7 & 0.2 & 0.1 \\
	0    & 0.6 & 0.4 \\
	0 .5 & 0  & 0.5 \\
\end{matrix}\right)
$$
Determina las probabilidades 
$$
P(X_3=1\vert X_0=0)\quad \mbox{y}\quad P(X_4=1\vert X_0=0)
$$
\item La cadena de Markov $\{X_n\}$, con espacio de estados, $S =\{0,1,2\}$ tiene matriz de transición:
$$
P = \left(\begin{matrix}
	0 .3 & 0.2 & 0.5 \\
	0.5  & 0.1 & 0.4 \\
	0 .5 & 0.2  & 0.3 \\
\end{matrix}\right)
$$
Determina las probabilidades 
$$
P(X_3=1\vert X_0=0)\quad \mbox{y}\quad P(X_4=1\vert X_1=0)
$$
\item Considera la cadena de Markov con matriz de transición:

$$
P = \bordermatrix{~ & 0   & 1   & 2 & 3 \cr
                  0 & 0.4 & 0.3 & 0.2 & 0.1 \cr
                  1 & 0.1 & 0.4 & 0.3 & 0.2\cr
                  2 & 0.3 & 0.2 & 0.1 & 0.4 \cr
                  3 & 0.2 & 0.1 & 0.4 & 0.3\cr             
                  }
$$
Supongamos que la distribución inicial es $\pi_0(i)=1/4$ para $i = 0,1,2,3$. Muestra que $P(X_n = k) = 1/4$ para $k = 0,1,2,3$ y para toda $n$. ¿Puedes deducir algún resultado general a partir de este ejemplo?
\item Supongamos que $X_n$ denota la calidad del $n$-ésimo artículo producido en una fábrica. Donde $X_n=0$ significa que el producto es defectuoso y $X_n=1$ significa que el producto es bueno. Supongamos que $\{X_n\}$ evoluciona como una cadena de Markov con matriz de transición:

$$
P = \bordermatrix{~ & 0   & 1   \cr
                  0 & 0.99 & 0.01 \cr
                  1 & 0.12 & 0.88 \cr
                  }
$$
¿Cuál es la probabilidad de que el cuarto artículo este defectuoso dado que el primero también salió defectuoso?
\item Supongamos que $\{X_n\}$ es una cadena de Markov con matriz de transición:

$$
P = \bordermatrix{~ & 0   & 1   \cr
                  0 & \alpha & 1-\alpha \cr
                  1 & 1-\beta & \beta \cr
                  }
$$
Entonces $Z_n= (X_{n-1},X_n)$ es una cadena de Markov con estados $(0,0)$, $(0,1)$, $(1,0)$, $(1,1)$. Determina la matriz de transición.
\item La cadena de Markov $\{X_n\}$, tiene matriz de transición:

$$
P = \bordermatrix{~ & 0   & 1   & 2 \cr
                  0 & 0.7 & 0.2 & 0.1 \cr
                  1 & 0.3 & 0.5 & 0.2 \cr
                  2 & 0   & 0   & 1 \cr             
                  }
$$
Sabemos que la cadena empieza en $X_0=1$. Sea
$$
T = min\{n>0; X_n =2\}
$$
El primer momento en que la cadena visita al estado 2. Calcula $P(X_3=0\vert X_0, T>3)$.
Hint: El evento $\{T>3\}$ es igual al evento $\{X_3\neq 2\}=\{X_3=0\}\cup\{X_3=1\}$.
\item Tres bolas blancas y tres bolas negras son distribuidas aleatoriamente en dos urnas, de modo que cada urna tiene tres bolas Decimos que el sistema esta en el estado $i$, $i = 0,1,2,3$ si la primera urna contiene $i$ bolas blancas. En cada paso extraemos una bola de la urna 1 y una bola de urna 2 y las intercambiamos. Calcula la probabilidad inicial de la cadena y exhibe la matriz de transición.
\item Supongamos que el evento de que llueva o no el día de hoy, depende de el clima en los últimos tres días. ¿Que espacio de estados sugieres para tratar a este sistema como cadena de Markov?

supongamos que si ha llovido en los últimos tres días, entonces lloverá hoy con una probabilidad del 0.8, si no llovió en ninguno de los tres días previos, entonces el día de hoy lloverá con una probabilidad de 0.2. En cualquier otro caso, el clima será igual que el día de ayer con probabilidad 0.6. Determina la matriz de transición de la cadena de Markov.
\item Sea $\{X_n\}$ una cadena de Markov con matriz de transición:

$$
P = \bordermatrix{~ & 0   & 1   & 2 \cr
                  0 & 1/2 & 1/3 & 1/6 \cr
                  1 & 0   & 1/3 & 2/3 \cr
                  2 & 1/2 & 0   & 1/2 \cr             
                  }
$$
Si $\pi_0(0) = \pi_0(1)=1/4$, encuentra $E[X_3]$.
\end{enumerate}

\end{document}