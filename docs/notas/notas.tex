\documentclass{extreport}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{theoremref}
\usepackage{mathpazo}
%\setlength{\parskip}{1em}
\usepackage{tikz}
\usetikzlibrary{babel}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={160mm,245mm},
 left=25mm,
 top=20mm,
 }

%\usepackage{mdframed}
%\usepackage[framemethod=TikZ]{mdframed}
\usepackage[framemethod=TikZ]{mdframed}


\newcounter{example}[chapter]
\newenvironment{example}[1][]{\refstepcounter{example}\par\medskip
   \noindent\textbf{Ejemplo~\thechapter.\theexample. #1 }\par\medskip\hrule \rmfamily\par\medskip}{\medskip\hrule\medskip}


\newmdenv[linecolor=red,frametitle=Infobox]{infobox}

%\surroundwithmdframed[linewidth=1pt, roundcorner=10pt, %backgroundcolor=gray!10]{example}


 \newtheoremstyle{definicion}%
    {3pt}%
    {3pt}%
    {}%
    {}%
    {\bfseries}%
    {.}%
    {\newline}%
    {}%
    

\theoremstyle{definicion}
\newtheorem{definition}{Definición}[chapter]

\surroundwithmdframed[linewidth=1pt, roundcorner=10pt, backgroundcolor=gray!10]{definition}

\newtheoremstyle{propiedad}%
    {-1pt}%
    {3pt}%
    {\itshape}% Fuente del cuerpo
    {}%
    {\bfseries}%  Fuente del encabezado
    {.}%
    {\newline}%
    {}%
\theoremstyle{propiedad}
\newtheorem{propiedad}{Propiedad}[chapter]
\surroundwithmdframed[linewidth=1pt, roundcorner=10pt, backgroundcolor=gray!10]{propiedad}

\newtheoremstyle{teorema}%
    {-1pt}%
    {3pt}%
    {\itshape}% Fuente del cuerpo
    {}%
    {\bfseries}%  Fuente del encabezado
    {.}%
    {\newline}%
    {}%
\theoremstyle{teorema}
\newtheorem{teorema}{Teorema}[chapter]
\surroundwithmdframed[linewidth=1pt, roundcorner=10pt, backgroundcolor=gray!10]{teorema}


\makeatletter
\renewenvironment{proof}[1][\proofname]{\par
    \pushQED{\qed}%
    \normalfont \topsep6\p@\@plus6\p@\relax
    \trivlist
    \item\relax
            {\itshape
        #1\@addpunct{.}}\hspace\labelsep\ignorespaces
}{%
    \popQED\endtrivlist\@endpefalse
}
\makeatother
\decimalpoint

%\usepackage{parskip}
%\usepackage[skip=10pt plus1pt, indent=10pt]{parskip}

%\usepackage{parskip}


\begin{document}
\chapter{Probabilidad} 
    

El primer paso al proponer un modelo probabilístico consiste en determinar todo aquello que consideramos posible. 

\begin{definition}
Al conjunto de todo aquello que consideramos \emph{posible} se le conoce  como \emph{espacio muestral}. Es costumbre denotar al espacio muestral con $\Omega$. A un elemento $\omega \in \Omega$ se le conoce como \emph{ocurrencia} o \emph{punto muestral}.
\end{definition}

Por ejemplo, si lanzamos una moneda, lo mas natural es suponer que la moneda caerá en una de sus dos caras, águila ($A$) o sol ($S$). En este caso 

$$
\Omega =\left\{A, S\right\} 
$$
parece ser una buena propuesta. 

Si lanzamos un par de dados, el espacio muestral mas lógico sería el conjunto:

$$
\Omega = \left\{(i, j): i, j = 1,2,\ldots,6\right\}
$$
o bien:
$$
\Omega = \left[
\begin{matrix}
(1,1) & (1,2) & (1,3) & (1,4) & (1,5) & (1,6) \\

(2,1) & (2,2) & (2,3) & (2,4) & (2,5) & (2,6) \\

(3,1) & (3,2) & (3,3) & (3,4) & (3,5) & (3,6) \\

(4,1) & (4,2) & (4,3) & (4,4) & (4,5) & (4,6) \\

(5,1) & (5,2) & (5,3) & (5,4) & (5,5) & (5,6) \\

(6,1) & (6,2) & (6,3) & (6,4) & (6,5) & (6,6) \\

\end{matrix}
\right]
$$

Otro ejemplo: si lo que registramos es el tiempo desde que llegamos al andén y hasta que llega el metro entonces podríamos proponer:

$$
\Omega = [0,\infty)
$$

La manera de definir el espacio muestral es por completo decisión de quien modela el experimento aleatorio.  

\begin{example}\label{ex:1}
Otro buen ejemplo es el siguiente, supongamos que lanzamos tres monedas. Si en un lanzamiento sale sol ganamos un peso y si sale águila perdemos un peso. Claramente nos interesa saber cuál será nuestra ganancia (pérdida) total al final de los tres lanzamientos. Empecemos por proponer un espacio muestral:

$$
\Omega = \left\{\omega = (\nu_1, \nu_2, \nu_3): \nu_i \in\{A,S\}\text{ para } i = 1,2,3 \right\}.
$$

Esta propuesta es conveniente para la idea que deseamos desarrollar, sin embargo no es para nada la única. De nuevo, la definición de $\Omega$ depende por completo de las necesidades de quien modela el experimento aleatorio.

Un elemento particular de $\Omega$ es por ejemplo: $\omega = (S,A,S)$. En este escenario, ganamos un peso en el primer lanzamiento, perdimos un peso en el segundo y ganamos uno en el tercero. En total tendríamos una ganancia de 1 peso después de lanzar tres veces la moneda. Si  $\omega = (S,S,S)$ entonces ganamos en los tres lanzamientos y por tanto tendremos 3 pesos al final del juego. En un escenario menos afortunado, si $\omega = (A,S,A)$ entonces habremos perdido en dos de los tres lanzamientos y por tanto nuestra pérdida final será de $-1$ pesos. 

Pongamos un poco de orden y reescribamos $\Omega$ de forma explícita:

\begin{align*}
        \Omega =  & \left\{(SSS), (SSA), (SAS), (SAA) \right.\\
                  & \left. (ASS), (ASA), (AAS), (AAA) \right\}
\end{align*}
y agrupemos:
\begin{equation*}
    \begin{split}
        A_3 & = \left\{(SSS)\right\}\\
        A_1 & = \left\{(SSA), (SAS), (ASS)\right\}\\
        A_{-1} & = \left\{(SAA), (ASA), (AAS)\right\}\\
        A_{-3} & = \left\{(AAA)\right\}\\
    \end{split}
\end{equation*}

Son justamente los casos en $A_3$ donde ganamos un tres pesos, en $A_1$ ganamos un peso, en $A_{-1}$ perdemos un peso y en $A_{-3}$ perdemos tres pesos. Pero podemos hacer aún mas, observemos por ejemplo que:
$$
A_3 \cup A_1 = \text{``Casos donde ganamos al menos un peso''}
$$
o bien
$$
A_3^c = \text{``Perdimos al menos un volado''}
$$
Una interpretación parecida podemos darle a cualquier otro subconjunto de $\Omega$ definido a partir de los subconjuntos $A_3$, $A_1$, $A_{-1}$ y $A_{-3}$. 
\end{example}

La idea mas importante que debemos extraer del ejemplo anterior es entender que cada uno de estos subconjuntos representa información, información que puede ser de gran valor. Si este es el caso, sería natural pensar en trabajar con la potencia de $\Omega$ al momento de desarrollar un modelo probabilístico. En algunos casos simples esto es posible, aunque quizás no fuese conveniente, sin embargo en otros casos ni siquiera es posible. Particularmente cuando $\Omega$ es infinito, trabajar con $2^\Omega$ puede conducirnos a situaciones donde no sea posible definir una noción de probabilidad para todos los subconjuntos de $\Omega$. Por esta razón es conveniente trabajar con una colección de subconjuntos de $\Omega$ un poco mas ``controlada'', esta es la idea de la siguiente definición. 
\begin{definition}[$\sigma$-álgebra]
    Dado un conjunto $\Omega$ decimos que la colección $\mathcal{F}$ de subconjuntos de $\Omega$ es una $\sigma$-\emph{álgebra} si:
    \begin{enumerate}
        \item $\Omega \in \mathcal{F}$
        \item Si $A\in \mathcal{F}$ entonces $A^c \in \mathcal{F}$
        \item Si $\left\{A_i\right\}_{I}$ es una colección numerable de subconjuntos en $\mathcal{F}$ entonces:
        $$
            \bigcup_{i\in I} A_i \in \mathcal{F}
        $$
    \end{enumerate}
\end{definition}
\par\noindent
Al par $(\Omega, \mathcal{F})$  se le conoce como \emph{espacio medible}. A un subconjunto $A\in \mathcal{F}$ lo llamamos \emph{evento}. Adicionalmente, decimos que un evento $A$ \emph{ocurre} si después de ejecutar un experimento aleatorio el $\omega$ observado pertenece a $A$.

Es importante subrayar que la unión que presentamos en el inciso 3 de la definición de $\sigma$-álgebra debe ser una unión \textbf{numerable}, uniones arbitrarias de elementos en la $\sigma$-álgebra, no necesariamente pertenecen a ella. Notemos que la definición también implica cerradura bajo uniones finitas. Para mostrar esto notemos primero que $\emptyset = \Omega^c \in \mathcal{F}$.  Ahora, si $A$ y $B$ son dos subconjuntos en $\mathcal{F}$, construimos la sucesión $\left\{A_i\right\}$ haciendo $A_1 = A$, $A_2 = B$ y $A_i = \emptyset$ para $i= 3,4,\ldots$ de modo  que  $\left\{A_i\right\}\subset \mathcal{F}$ . En consecuencia:
$$
A \cup B = \bigcup_{i = 1}^\infty A_i \in \mathcal{F}
$$
lo cual prueba que una $\sigma$-álgebra también es cerrada bajo uniones finitas. 

Dado un conjunto $\Omega$, la $\sigma$-álgebra de subconjuntos de $\Omega$ mas pequeña que podemos definir es:

$$
\mathcal{F} = \left\{\emptyset, \Omega\right\}.
$$
En contraste, la $\sigma$-álgebra de subconjuntos de $\Omega$  mas grande que podemos construir es $2^\Omega$. No es difícil demostrar este par de aseveraciones. Otros dos ejemplos populares son los siguientes: si $A\subset \Omega$, la colección:

$$
\mathcal{F} = \left\{\emptyset, A, A^c,\Omega\right\}
$$
es una $\sigma$-álgebra.

Un ejemplo un poco mas retador lo encontramos con la colección de subconjuntos:

$$
\mathcal{F} = \left\{A\subset \Omega: A \text{ es numerable o } A^c \text{es numerable}\right\}
$$
$\mathcal{F}$ es una $\sigma$-álgebra. Para probar esto debemos verificar que $\mathcal{F}$ cumple con los 3 incisos en la definición de $\sigma$-álgebra, para ello observemos que como $\emptyset$ es numerable entonces $\Omega\in \mathcal{F}$. Por otro lado, es evidente que si $A\in \mathcal{F}$ entonces $A^c\in \mathcal{F}$. Por ultimo, consideremos una sucesión $\{A_i\}$ de subconjuntos en $\mathcal{F}$. Es decir,$A_i$ es numerable o bien $A_i^c$ es numerable, para toda $i$. Si $A_i$ es numerable para toda $i$ entonces $\cup_iA_i$ es numerable y por tanto $\cup_i A_i\in \mathcal{F}$. Por el contrario, si existe $i$ tal que $A_i$ es no numerable entonces $A_i^c$ es numerable, por lo tanto: $\left(\cup_iA_i\right)^c = \cap_iA_i^c$ si es numerable. En consecuencia $\cup_iA_i\in \mathcal{F}$, con lo cual demostramos que $\mathcal{F}$ es una $\sigma$-álgebra.

\begin{definition}
Dada una colección $\mathcal{C}$ de subconjuntos de $\Omega$, definimos a la $\sigma$-álgebra generada por $\mathcal{C}$ como la $\sigma$-álgebra mas pequeña que contiene a $\mathcal{C}$. A esta $\sigma$-álgebra la denotamos con $\sigma(\mathcal{C})$.    
\end{definition}

Si $\left\{\mathcal{F}_i\right\}_I$ es una colección de $\sigma$-álgebras, entonces $\cap_I \mathcal{F}_i$ es $\sigma$-álgebra.  Esta afirmación no es difícil de probar y es válida para cualquier colección de $\sigma$-álgebras. La unión de $\sigma$-álgebras no necesariamente devuelve otra $\sigma$-álgebra. Esta observación nos conduce a una propiedad directamente relacionada con la definición anterior.

\begin{propiedad}
La $\sigma$-álgebra $\sigma(\mathcal{C})$ generada por la colección $\mathcal{C}$ coincide con la intersección de todas las $\sigma$-álgebras que contienen a la colección $\mathcal{C}$.
\end{propiedad}
\begin{proof}
\par Esto se verifica fácilmente, si $\Xi$ es la colección de todas las $\sigma$-álgebras que contienen a $\mathcal{C}$ entonces $2^\Omega\in\Xi$, con lo cual existe al menos una $\sigma$-álgebra que contiene a $\mathcal{C}$. Observemos además que $\sigma(\mathcal{C})\in\Xi$, por lo tanto 

$$
\bigcap_{\mathcal{H}\in\Xi}\mathcal{H} \subset \sigma(\mathcal{C})
$$

pero como $\cap_{\mathcal{H}\in \Xi}\mathcal{H}$ es $\sigma$-álgebra entonces $\sigma(\mathcal{C})\subset\cap_{\mathcal{H}\in\Xi}\mathcal{H}$ y por tanto $\sigma(\mathcal{C})=\cap_{\mathcal{H}\in\Xi}\mathcal{H}$
\end{proof}

\begin{definition}
La $\sigma$-álgebra de Borel definida en $\mathbb{R}$ es la $\sigma$-álgebra generada por los abiertos    
\end{definition}

La idea de la $\sigma$-álgebra de Borel tiene sentido en cualquier espacio topológico sin embargo cuando la definimos en los reales podemos dar descripciones alternativas. Por lo pronto, notemos que todos los intervalos abiertos pertenecen a $\mathcal{B}.$ Pero además, como todo abierto en $\mathbb{R}$ puede ser expresado como unión numerable de intervalos abiertos, concluimos que $\mathcal{B}$ es también generada por los intervalos abiertos. Por otro lado, la cerradura bajo complementos de $\mathcal{B}$ nos garantiza que todo cerrado también está en $\mathcal{B}$, por lo tanto los intervalos cerrados están en $\mathcal{B}$. Particularmente los intervalos cerrados del tipo $(-\infty, x]$ también están en $\mathcal{B}$. De hecho también podemos generar a $\mathcal{B}$ con estos intervalos. La $\sigma$-álgebra de Borel es en realidad una colección muy rica de subconjuntos de $\mathbb{R}$, es sorprendentemente complicado construir un subconjunto de $\mathbb{R}$ que no este en $\mathcal{B}$.  Este ejemplo será de gran importancia en lo sucesivo.

Una de las funciones principales de una $\sigma$-álgebra es la de servir de dominio para una medida de probabilidad:

\begin{definition}
Una función $P:\mathcal{F}\rightarrow [0,1]$  es una medida de probabilidad si:
\begin{enumerate}
    \item $P(\Omega) = 1$
    \item Si $\left\{A_i\right\}$ es una colección numerable de elementos disjuntos de $\mathcal{F}$ entonces:
    $$
        P\left(\bigcup_{i\in I} A_i\right) =  \sum_{i\in I} P(A_i) 
    $$
\end{enumerate}    
\end{definition}

A la tercia $(\Omega, \mathcal{F}, P)$ se le conoce como \emph{espacio de probabilidad}. Hacemos énfasis en que la medida $P$ solo opera sobre subconjuntos de $\Omega$ que esten en $\mathcal{F}$, si $A\subset \Omega$ pero $A\notin \mathcal{F}$, entonces no existe forma de definir una probabilidad sobre $A$.

Es importante notar que la colección del inciso 2 no solo es una colección numerable, es también una colección de disjuntos. 


\begin{definition}
Sea $f:X\rightarrow Y$ y $E\subset Y$. Definimos la \emph{preimagen}  de $E$ como:

$$
f^{-1}(E) := \left\{x\in X: f(x) \in E\right\}
$$    
\end{definition}
\par\noindent

Dicho de otro modo, la preimagen de un conjunto $E$  son todos aquellos elementos de $X$  que al ser evaluados en la función $f$  van a dar al conjunto $E.$ Esta idea es fundamental en la definición siguiente: 

\begin{definition}[Variable aleatoria]
Dado un espacio de probabilidad $(\Omega, \mathcal{F}, P)$  decimos que una \emph{variable aleatoria} es una función $X:\Omega \rightarrow \mathbb{R}$ tal que 

$$
\left\{X \in B\right\} = X^{-1}(B)\in \mathcal{F}
$$
para todo $B\in \mathcal{B}$. 

La $\sigma$-álgebra generada por los conjuntos de la forma $X^{-1}(B)$ con $B\in\mathcal{B}$ se conoce como la \emph{$\sigma$-álgebra generada por $X$} y la denotamos con $\sigma(X)$.
    
\end{definition}

\begin{example}
    Supongamos que lanzamos un par de dados, el espacio muestral mas natural para este experimento es el conjunto:

$$
\Omega = \left\{(i,j): i, i = 1,2,\ldots, 6\right\}
$$


En un espacio muestral finito como este es fácil definir una $\sigma$-álgebra que funcione satisfactoriamente. Basta con hacer $\mathcal{F}= 2^\Omega$ e inmediatamente tenemos un espacio medible $(\Omega, \mathcal{F})$ donde podemos definir la medida de probabilidad:

$$
P(\{(i,j)\}) = 1/36\quad \text{ para } i,j= 1,2,\ldots, 6 
$$

Notemos que cualquier elemento de $\mathcal{F}$ puede obtenerse mediante operaciones de conjuntos sobre  elementos de la colección:

$$
\mathcal{C} = \left\{\{(i,j)\}: i,j= 1,2,\ldots,6\right\}
$$
Aunque de hecho es incluso mas simple; cualquier elemento de $\mathcal{F}$ puede construirse a través de uniones de conjuntos en $\mathcal{C}$. Observemos que todas las posibles uniones que podemos formar coinciden con el número de subconjuntos de $\mathcal{C}$, es decir $\mathcal{F}$  contiene $2^{36}$ elementos.

Por otro lado consideremos la variable aleatoria $X$ que calcula la suma de las caras de los dos dados. Tenemos por lo pronto que:    

$$
X:\Omega \rightarrow \{2,\ldots, 12\}\subset \mathbb{R}
$$
Esta variable aleatoria define la colección de subconjuntos de $\Omega$:
$$
\mathcal{D} = \left\{ X^{-1}(i),i =2,3\ldots 12\right\}
$$
donde 
$$
X^{-1}(i) = \left\{\omega\in\Omega: X(\omega)=i\right\}
$$
para $i=2,3\ldots, 12.$  Es decir, $X^{-1}(i)$ es el evento donde la suma de los dados sea igual a $i = 2,3,\ldots, 12$. No es difícil convencerse de que la colección ${\mathcal F}_{+}$ de todas las posibles uniones de elementos en $\mathcal{C}$ es una $\sigma$-álgebra, de hecho $\mathcal{F}_+ = \sigma(\mathcal{D}) = \sigma(X)$. Sin embargo notemos que en este caso el número total de uniones de elementos de $\mathcal{D}$ y en consecuencia el número total de elementos de $\sigma(X)$ es igual a $2^{11}$. Un número bastante menor que los $2^{36}$ elementos que tiene $\mathcal F$.

Ambas $\sigma$-álgebras son de utilidad, sin embargo mientras $\mathcal{F}$ contiene toda la información posible que pudiésemos extraer del experimento de lanzar un par de dados, la $\sigma$-álgebra $\mathcal F_{+}$ contiene la información que se deduce de observar los valores que toma la variable aleatoria $X$. 
\end{example}
Aunque no es indispensable para la exposición que queremos hacer en este repaso en el ánimo de conseguir cierta completez ofrecemos la siguiente definición.
\begin{definition}
    Dado un espacio de probabilidad $(\Omega, \mathcal{F}, P)$, decimos que la medida de probabilidad $P_X$ definida en el espacio medible $(\mathbb{R}, \mathcal{B})$ como:
    $$
    P_X(B) = P\left(X\in B\right)  = P(X^{-1}(B))
    $$
    para todo $B\in\mathcal{B}$ es la \emph{distribución} de $X$.
\end{definition}

De acuerdo con la definición anterior, una variable aleatoria $X$, no solo mapea el conjunto $\Omega$ en los reales, de hecho mapea todo el espacio de probabilidad $(\Omega, \mathcal{F}, P)$ en el espacio de probabilidad $(\mathbb{R}, \mathcal{B}, P_X)$. 

\begin{definition}
    Dado un espacio de probabilidad $(\Omega, \mathcal{F}, P)$ y una $\sigma$-álgebra $\mathcal{G}\subset\mathcal{F}$. Decimos que $A\in\mathcal{F}$ es \emph{$\mathcal{G}$-medible} si $A\in\mathcal{G}$. 

     A su vez, decimos que la variable aleatoria $X$ es $\mathcal{G}$-medible si $\sigma(X)\subset\mathcal{G}$. 
\end{definition}




Ejemplo

En finanzas existen muchas formas de modelar la dinámica de precios para los diferentes activos en el mercado. De hecho estos modelos varían considerablemente de acuerdo con la naturaleza del activo. Aquí proponemos un modelo extremadamente simple pero no por ello inútil.

Supongamos que al tiempo $t$ el precio de un activo es $S_t$   si vivimos justamente en el tiempo $t$, el precio $S_t$ es conocido, sin embargo los precios en días futuros no lo son. Uno de los modelos discretos mas populares supone la siguiente dinámica para el proceso de precios:

$$
S_{t+1} = \begin{cases}uS_t & \text{con probabilidad } p \\
dS_t & \text{con probabilidad } 1-p\end{cases}
$$

Un supuesto mas económico que probabilístico es que $u>1$ y $0< d < 1$.  Si $S_{t+1} = uS_t$ entonces observamos un alza de precios, si $S_{t+1} = dS_t$ entonces hemos observado una baja. El modelo puede parecer muy simple a primera vista, sin embargo veremos que al introducir múltiples periodos de observación, el modelo se enriquece de forma considerable. Sin embargo este modelo nos ofrece la posibilidad de estudiar una serie de ideas tanto financieras como probabilísticas, en un ambiente simple y controlado.

\section{Esperanza condicional.}

Sea $X$ una variable aleatoria definida en un espacio de probabilidad $(\Omega, \mathcal{F}, P)$ y  $\mathcal{G}$  una sub $\sigma$-álgebra de $\mathcal{F}$.  Decimos que $X$ es $\mathcal{G}$-*medible* si $\sigma(X)\subset \mathcal{G}$. Esto lo interpretamos diciendo que si conocemos la información de $\mathcal{G}$ entonces conocemos la información de $X$. De este modo, la información en $\mathcal{G}$ es suficiente para determinar el valor de $X$. 

$X$ es independiente de $\mathcal{G}$ si:

$$
P(A\cap B) = P(A)P(B)
$$

para todo $A\in \sigma(X)$ y $B\in\mathcal{G}$. Si $X$ es independiente de $\mathcal{G}$ entonces la información de $\mathcal{G}$ es irrelevante para determinar el valor de $X.$ Los casos recién expuestos son los casos extremos, por en el primero la información en $\mathcal{G}$ es suficiente para determinar el valor de $X$ y en el segundo, la información en $\mathcal{G}$ es irrelevante. Existe un caso intermedio: si $X$ y $\mathcal{G}$ no son independientes y  $X$ no es $\mathcal{G}$-medible, entonces la información en $\mathcal{G}$ ayuda a determinar un estimado del valor de $X$ aunque no lo determine del todo. La *esperanza condicional de $X$  dado $\mathcal{G}$* es justamente la herramienta que utilizamos para dar esta estimación.

Consideremos nuevamente nuestro modelo de precios, y recordemos la filtración $\{\mathcal{F}_i\}$ que propusimos, donde: $\mathcal{F_t} = \left\{\emptyset, \Omega\right\}$, $\mathcal{F}_{t+1} = \sigma(\mathcal{C}_1)$, $\mathcal{F}_{t+2} = \sigma(\mathcal{C}_2)$ y $\mathcal{F}_{t+3} = 2^\Omega$.

donde:

 

$$
\mathcal{C}_1 = \left\{A_u, A_d\right\}
$$

con:


\begin{align*}
A_u & = \left\{(u,u,u),(u,u,d),(u,d,u),(u,d,d)\right\} \\
A_d & = \left\{(d,u,u),(d,u,d),(d,d,u),(d,d,d)\right\} 
\end{align*}


y 

$$
\mathcal{C}_2= \{A_{uu}, A_{ud}, A_{du}, A_{dd}\}
$$

con:


\begin{align*}
A_{uu} & = \left\{(u,u,u),(u,u,d)\right\} \\
A_{ud} & = \left\{(u,d,u),(u,d,d)\right\}\\ 
A_{du} & = \left\{(d,u,u),(d,u,d)\right\} \\
A_{dd} & = \left\{(d,d,u),(d,d,d)\right\}
\end{align*}


las $\sigma$-álgebras en la filtración $\left\{\mathcal{F}_{t+i}\right\}$, $i=0,1,2,3$ recogen la información que se deduce de observar las trayectorias del proceso $\omega = (\nu_1, \nu_2, \nu_2)$.  Estas trayectorias de algún modo “cuentan” la historia detallada del proceso, sin embargo no siempre es indispensable conocer cada detalle, consideremos por ejemplo la filtración: $\mathcal{G}_t = \left\{\emptyset, \Omega\right\}$, $\mathcal{G}_{t+1} = \sigma(\mathcal{D}_{t+1})$, $\mathcal{G}_{t+2} = \sigma(\mathcal{D}_{t+2})$ y $\mathcal{G}_{t+3} = \sigma(\mathcal{D}_{t+3})$, donde:


\begin{align*}
\mathcal{D}_{t+1} & = \left\{A_u, A_d\right\}\\
\mathcal{D}_{t+2} & = \left\{A_{uu}, A_{ud}\cup A_{du}, A_{dd}\right\}\\
\mathcal{D}_{t+3}&  = \left\{A_{u^3}, A_{u^2d}, A_{ud^2}, A_{d^3}\right\}
\end{align*}


con:


\begin{align*}
A_{u^3} & = \left\{(u,u,u)\right\}\\
A_{u^2d} & = \left\{(u,u,d),(u,d,u),(d,u,u)\right\}\\ 
A_{ud^2} & = \left\{(u,d,d),(d,u,d), (d,d,u)\right\} \\
A_{d^3} & = \left\{(d,d,d)\right\}
\end{align*}


Notemos como ejemplo que 


\begin{align*}
S_{t+3}^{-1}(u^3S_t) & = A_{u^3}\\
S_{t+3}^{-1}(u^2dS_t) & = A_{u^2d}\\
S_{t+3}^{-1}(ud^2S_t) & = A_{ud^2}\\
S_{t+3}^{-1}(d^3S_t) & = A_{d^3}\\ 
\end{align*}


de modo que  $\sigma(S_{t+3}) = \sigma(D_{t+3})$, de hecho: $\mathcal{G}_{t+i} = \sigma(S_{t+i})$ para $i = 0,1,2,3$. Las $\sigma$-algebras $\mathcal{G_{t+i}}$ cuentan la historia desde la observación de los precios $S_{t+i}$ a diferencia  de las $\sigma$-álgebras $\mathcal{F}_{t+i}$ que cuentan la historia de las trayectorias $\omega = (\nu_1, \nu_2, \nu_3)$. De hecho observemos que para $i= 0, 1, 2,3$ tenemos que $\mathcal{G}_{t+i}\subset\mathcal{F}_{t+1}$, lo cual implica que la filtración $\{\mathcal{F}_{t+i}\}$ acumula en cada periodo tanta información o mas que la filtración $\{\mathcal{G}_{t+i}\}$. Esto nos conduce a la siguiente idea.

Dado un espacio de probabilidad filtrado $(\Omega, \mathcal{F}, P, \{\mathcal{F}_{t+i}\})$ decimos que el proceso $\{X_{t+i}\}$ es *adaptable a la filtración* si $\sigma(X_{t+i})\subset \mathcal{F}_{t+i}$ para toda $i$,  es decir si cada $X_{t+i}$ es $\mathcal{F}_{t+i}$-medible. Esto quiere decir que  la información proveída por la filtración $\{\mathcal{F}_{t+i}\}$ es tan rica o mas que la información proveída por el proceso $X_{t+i}$. Si  conocemos la información de $\mathcal{F}_{t+i}$ entonces seremos capaces de determinar el valor de $X_{t+i}$. En nuestro ejemplo el proceso ${S_{t+i}}$ es adaptable a la filtración; $\sigma(S_{t+i})\subset \mathcal{F}_{t+i}$, oséa $S_{t+i}$ es $\mathcal{F}_{t+i}$-medible.

Si bien el proceso $\{S_{t+i}\}$ es adaptado a la filtración y $S_{t+i}$  es $\mathcal{F}_{t+i}$-medible, $S_{t+i+1}$ **no** es $\mathcal{F}_{t+i}$ medible. Por ejemplo, $S_{t+2}$ es $\mathcal{F}_{t+2}$-medible pero $S_{t+3}$ **no** es $\mathcal{F}_{t+2}$-medible, es decir; $\mathcal{F}_{t+2}$ no contiene información suficiente como para determinar el valor de $S_{t+3}$, sin embargo esto no implica que $S_{t+3}$ y $\mathcal{F}_{t+2}$ sean independientes, definitivamente, la información en $\mathcal{F}_{t+2}$ modifica el valor estimado de $S_{t+3}$ aunque no lo determine completamente. En este sentido la esperanza:

$$
E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right]
$$

es una variable aleatoria.

De hecho si:

$$
S_{t+1} =\begin{cases}
uS_t & \text{con probabilidad }p\\
dS_t & \text{con probabilidad }1-p\\
\end{cases}
$$

entonces:


\begin{align*}
E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right](A_{uu}) & = p S_{t+3}(uuu) + (1-p)S_{t+3}(uud)\\
E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right](A_{ud}) & = p S_{t+3}(udu) + (1-p)S_{t+3}(udd)\\
E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right](A_{du}) & = p S_{t+3}(duu) + (1-p)S_{t+3}(dud)\\
E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right](A_{dd}) & = p S_{t+3}(ddu) + (1-p)S_{t+3}(ddd)
\end{align*}


Conociendo la información


\begin{align*}
E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right](A_{uu})P(A_{uu}) & = \sum_{\omega \in A_{uu}}S_{t+3}(\omega)P(\{\omega\})\\
E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right](A_{ud})P(A_{ud}) & = \sum_{\omega \in A_{ud}}S_{t+3}(\omega)P(\{\omega\})\\
E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right](A_{du})P(A_{du}) & = \sum_{\omega \in A_{du}}S_{t+3}(\omega)P(\{\omega\})\\
E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right](A_{dd})P(A_{dd}) & = \sum_{\omega \in A_{dd}}S_{t+3}(\omega)P(\{\omega\})\\
\end{align*}


otra forma de escribir estas igualdades es como sigue:


\begin{align*}
\int_{A_{uu}}E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right](\omega)dP & = \int_{\omega \in A_{uu}}S_{t+3}(\omega)dP\\
\int_{A_{ud}}E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right](\omega)dP & = \int_{\omega \in A_{ud}}S_{t+3}(\omega)dP\\
\int_{A_{du}}E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right](\omega)dP & = \int_{\omega \in A_{du}}S_{t+3}(\omega)dP\\
\int_{A_{dd}}E\left[S_{t+3}\vert \mathcal{F}_{t+2}\right](\omega)dP & = \int_{\omega \in A_{dd}}S_{t+3}(\omega)dP\\
\end{align*}

\begin{definition}
Sea $X$ una variable aleatoria definida en un espacio de probabilidad $(\Omega, \mathcal{F}, P)$. Si $\mathcal{G}$ es una sub $\sigma$-álgebra de $\mathcal{F}$, decimos que la variable aleatoria $E\left[X\vert\mathcal{G}\right]$ es la \emph{esperanza condicional} de $X$ dado $\mathcal{G}$ si
\begin{enumerate}
    \item $E\left[X\vert \mathcal{G}\right]$ es $\mathcal{G}$-medible.
    \item $\int_A E\left[X\vert \mathcal{G}\right]dP = \int_A X dP$
\end{enumerate}
para todo $A\in \mathcal{F}$.    
\end{definition}

Como consecuencia inmediata enunciamos el siguiente teorema que se enuncia sin prueba:
\begin{teorema}
Sean $X$ y $Y$variables  aleatorias integrables, definidas en un espacio de probabilidad $(\Omega, \mathcal{F},P)$.   Tenemos entonces que:
\begin{enumerate}
    \item Si $\mathcal{G}$ es una sub $\sigma$-álgebra de $\mathcal{F}$ entonces:
        $$
        E\left[a X + bY +c\vert \mathcal{G}\right] = aE\left[X\vert \mathcal{G}\right] +bE\left[Y\vert \mathcal{G}\right] +c
        $$
    \item Si $Y$ es $\mathcal{G}$-medible, entonces $E\left[XY\vert \mathcal{G}\right] = YE\left[X\vert \mathcal{G}\right]$  
    \item Si $\mathcal{H}\subset\mathcal{G}$ son dos sub $\sigma$-algebras de $\mathcal{F}$  entonces
        $$
        E\left[E\left[X\vert \mathcal{G}\right]\vert \mathcal{H}\right] = E\left[X\vert \mathcal{H}\right]
        $$    
\end{enumerate}
\end{teorema}

El inciso 1. del teorema anterior exhibe una propiedad que esperábamos; la esperanza condicional es un operador lineal.  El inciso 2. tiene una interpretación bastante natural, si $Y$ es $\mathcal{G}$-medible, entonces el conocimiento de $\mathcal{G}$ determina el valor de $Y$, esto nos permite tratar a la variable $Y$ como si fuera una constante y sale de la esperanza como si en verdad lo fuera. A esta propiedad se le suele conocer como ``sacar la que es conocido''. El inciso 3. lo podemos interpretar diciendo que dada la información en $\mathcal{H}$, la esperanza condicional $E[X\vert \mathcal{G}]$ es un buen estimador de $X$.

A continuación ofrecemos una definición que por el momento no exploraremos, pero que pronto será una de nuestras herramientas mas importantes.
\begin{definition}
    Se $\{X_t\}$ un proceso estocástico definido en el espacio de probabilidad filtrado: $(\Omega, \mathcal{F}, P, \{\mathcal{F}_t\})$. Decimos que $\{X_t\}$ es una \emph{martingala} si:
    $$
    E\left[X_t\vert \mathcal{F}_s\right] = X_s
    $$
    para toda $s\leq t$.
\end{definition}
La propiedad de martingala se suele reexpresar diciendo que dada la información al tiempo $s\leq t$, el mejor estimado para $X_t$ es el valor conocido del proceso al tiempo $s$. El determinar si un proceso estocático es una martingala o no, es una manera muy importante de clasificar a un proceso aunque claro esta no es la única forma de hacerlo. Otra característica que distingue a un proceso estocástico, la encontramos en la definición a continuación:

\begin{definition}
Decimos que el proceso estocástico $\{X_t\}$ es \emph{estacionario} si para cualquier colección de tiempos $t_1, t_2, \ldots, t_n$ y cualquier $h$, la distribución conjunta de:
$$
(X_{t_1}, X_{t_2}, \ldots, X_{t_n}) \quad\text{ y }\quad (X_{t_1+h}, X_{t_2+h}, \ldots, X_{t_n+h})
$$
es la misma.
\end{definition}

Dicho de otro modo, un proceso estocástico es estacionario si no importa el momento del tiempo en el cual lo observamos, siempre y cuando lo observemos a lo largo de periodos de tiempo de la misma longitud. 

Sea $\{X_t\}$ un proceso estocástico, a la diferencia:
$$
X_t-X_s
$$
se le conoce como un \emph{incremento}. Este sencillo concepto nos conduce a la siguiente definición:
 \begin{definition}
     Decimos que un proceso estocástico $\{X_t\}$ es de \emph{incrementos independientes} si
     $$
     X_{t_4}- X_{t_3} \quad\text{ y }\quad X_{t_2}-X_{t_1}
     $$
     son independientes para toda $t_1 \leq t_2 < t_3\leq t_4$.
 \end{definition}
 Otra forma de decir que un proceso es de incrementos independientes es decir que los incrementos del proceso sobre intervalos no traslapados, son independientes.

\chapter{Movimiento Browniano}
\section{Caminata aleatoria}

Denotamos con $S_{t+i}$ al  precio de un activo al tiempo $t+i$ con $i=0,1,2,\ldots$ de algún modo estamos considerando que el tiempo “presente” es el tiempo $t$, de modo que el precio del activo en $t+i$ para $i>0$ es estocástico. En este contexto  la sucesión $\left\{S_t\right\}$ es un proceso estocástico, para el cual proponemos la dinámica: 

$$
S_{t+1} = \begin{cases}
    uS_t & u>1 \\ 
    dS_t & 0<d<1
\end{cases}
$$
una selección común para $u$ y $d$ es:
\begin{align*}
    u  & = e^{\sigma \sqrt{\Delta t}}\\
    d  & = e^{-\sigma \sqrt{\Delta t}}
\end{align*}

Si definimos la sucesión $\{Z_i\}$ de variables aleatorias independientes con distribución:

$$
Z_i = \begin{cases} \phantom{-}1 & \text{con probabilidad }p  \\ 
-1 & \text{con probabilidad }1-p\end{cases}
$$
para $i = 1,2,3,\ldots$, reescribimos la dinámica de precios como:
$$
S_{t+1} = S_te^{Z_1\sigma\sqrt{\Delta t}}
$$
en general:
$$
S_{t+i} = S_{t+i-1}e^{Z_{i}\sigma\sqrt{\Delta t}}
$$
de donde se sigue que:
$$
S_{t+n} = S_{t}e^{\sigma\sqrt{\Delta t}\sum_{i=1}^nZ_i}
$$
de aquí definimos el proceso $\{X_i\}$  como:
$$
X_n = X_{n-1} + Z_n
$$
con la condición inicial $X_0 = 0$. De modo que:

$$
X_n = \sum_{i=1}^n Z_i + X_0
$$

El proceso $\{X_i\}$ es conocido como \emph{caminata aleatoria}. Notemos que si bien la sucesión de variables aleatorias $\{Z_i\}$ es una sucesión de variables aleatorias independientes e idénticamente distribuidas, el proceso $\{X_i\}$ es una colección de variables aleatorias que si poseen una estructura de correlaciones. Por otro lado, aunque el espacio de estados de $\{Z_i\}$ es el conjunto $\{1,-1\}$ el espacio de estados de $\{X_i\}$ es $\mathbb{Z}$. 

En realidad, podemos definir la caminata aleatoria de forma mas general, basta con partir de una colección $\{Z_i\}$ de variables aleatorias independientes e idénticamente distribuidas  y hacer:
$$
X_n = \sum_{i=1}^n Z_i + X_0
$$
Inclusive podemos suponer que $X_0$ es tambien una variable aleatoria, de modo que la caminata aleatoria tendría además una distribución inicial: $P(X_0 = x)$. No es indispensable suponer una distribución específica para las variables $\{Z_i\}$, estas pueden tener cualquier distribución, discreta o continua. Sin embargo para el problema que deseamos exponer, seleccionamos la distribución:

$$
Z_i = \begin{cases} \phantom{-}1 & \text{con probabilidad }1/2  \\ 
-1 & \text{con probabilidad }1/2\end{cases}
$$

En este caso decimos que la caminata aleatoria es una \emph{caminata aleatoria simétrica}. Veremos mas tarde el valor de este supuesto.


\begin{propiedad}
    Sea $\{X_n\}$ es una caminata aleatoria simétrica, $\{X_n\}$ es un proceso de incrementos independientes.
\end{propiedad}
\begin{proof}
    Sea $\{X_n\}$ es una caminata aleatoria definida como:
    $$
    X_n = \sum_{i=1}^n Z_n+X_0 
    $$
    con $X_0= 0$. Para $m>n$ escribimos el incremento del proceso de $n$ a $m$ como:
    $$
    X_m - X_n = \sum_{n+1}^m Z_i
    $$
De este modo para $t_1\leq t_2<t_3\leq t_4$ tenemos que:
\begin{equation}
    X_{t_4} - X_{t_3} = \sum_{t_3+1}^{t_4} Z_i
    \label{incr:1}
\end{equation}
y
\begin{equation}
    X_{t_2} - X_{t_1} = \sum_{t_1+1}^{t_2} Z_i    
    \label{incr:2}
\end{equation}
La sumas en (\ref{incr:1}) y (\ref{incr:2}) son sumas de variables aleatorias independientes y  no tienen términos en común, por lo tanto $X_{t_4} - X_{t_3}$ y $X_{t_2}-X_{t_1}$ son independientes.
\end{proof}
La prueba que recién presentamos no requirió del supuesto de que la caminata aleatoria fuese simétrica, de hecho la propiedad es válida para cualquier caminata aleatoria, sin embargo queremos hacer  énfasis en la caminata aleatoria simétrica ya que es la que estaremos trabajando en lo sucesivo. En la siguiente propiedad si hacemos uso de este supuesto:
\begin{propiedad}
    Si $\{X_n\}$ es una caminata aleatoria simétrica, entonces 
    \begin{equation}
        E[X_t-X_s] = 0
        \label{rw:1}
    \end{equation}
y
    \begin{equation}
        Var\left(X_t-X_s\right) = t-s
        \label{rw:2}
    \end{equation}
\end{propiedad}
\begin{proof}
    Para demostrar (\ref{rw:1}) recordemos que:
    $$
    X_t-X_s = \sum_{s+1}^t Z_i
    $$
    por lo tanto:
    $$
    E\left[X_t-X_s\right] = \sum_{s+1}^t E[Z_i]
    $$
    pero:
    $$
    E[Z_i] = \frac{1}{2}\cdot 1 + \frac{1}{2}\cdot -1 = 0
    $$
    para toda $i$. Por lo tanto $E[X_t-X_s] = 0$.

    Por otro lado, como las variables $\{Z_i\}$ son independientes:
    $$
    Var\left[X_t-X_s \right] = \sum_{s+1}^t Var(Z_i)
    $$
    pero:
    $$
    Var(Z_i) = \frac{1}{2}(1)^2 + \frac{1}{2}(-1)^2 = 1
    $$
    por lo tanto:
    $$
    Var\left(X_t-X_s\right) = \sum_{s+1}^t 1 = t-s
    $$
\end{proof}


\begin{propiedad}
    La caminata aleatoria simétrica $\{X_n\}$ adaptada a la filtración, es una martingala.
\end{propiedad}
\begin{proof}
    La demostración es directa, para $s\leq t$
    \begin{equation*}
        \begin{split}
            E\left[X_t\vert \mathcal{F}_s\right] & = E\left[X_t-X_s + X_s\vert\mathcal{F}_s\right]\\
                                                 & = E\left[X_t-X_s\vert\mathcal{F}_s\right] + E\left[X_s\vert\mathcal{F}_s\right]\\
                                                 & = E\left[X_t-X_s\right] + E\left[X_s\vert\mathcal{F}_s\right]\\
                                                 & = X_s
        \end{split}
    \end{equation*}
\end{proof}
En la demostración anterior usamos la linealidad de la esperanza condicional en la segunda igualdad. En la tercera ocupamos el hecho de que la caminata aleatoria es de incrementos independientes y en la cuarta usamos el hecho de que $E[X_t-X_s] = 0$ junto con el hecho de que $\left\{X_n\right\}$ es un proceso adaptado a la filtración y por tanto $X_s$ es $\mathcal{F}_s$-medible.
\begin{definition}\thlabel{def:varquad:1}
    Sea $\{X_t\}$ un proceso estocástico definido en un espacio de probabilidad filtrado $(\Omega, \mathcal{F}, P, \left\{\mathcal{F}_t\right\})$. Consideremos la partición $s,s+1, \ldots, t-1, t $  del intervalo $[s, t]$. Definimos la \emph{variación cuadrática} de $\{X_t\}$ a lo largo de $[s,t]$ como:
    \begin{equation}
        \left\langle X_t, X_t\right\rangle(t-s) = \sum_{i=s+1}^t \left(X_{i} - X_{i-1}\right)^2
        \label{varquad:1}
    \end{equation}
\end{definition}
El siguiente teorema es resultado inmediato de esta definición:
\begin{teorema}
    Si $\left\{X_t\right\}$ es una caminata aleatoria simétrica, entonces:
        \begin{equation}
        \left\langle X_t, X_t\right\rangle(t-s) = t-s
        \label{varquad:rw}
    \end{equation}
\end{teorema}
\begin{proof}
    Esto es fácil de probar si observamos que 
    $$
    \left(X_{i} - X_{i-1}\right)^2  = 1
    $$
    para todo $i$. De modo que:
    \begin{equation*}
    \begin{split}
        \left\langle X_t, X_t\right\rangle(t-s) & = \sum_{i=s+1}^t \left(X_{i} - X_{i-1}\right)^2 \\
                                                & = \sum_{i=s+1}^t 1 \\
                                                & = t-s
    \end{split} 
    \end{equation*}
\end{proof}
Notemos algunos detalles, la definición (\ref{def:varquad:1}) es en realidad una definición preliminar, sirve para nuestro propósito de definir una variación cuadrática para una caminata aleatoria simétrica, sin embargo una definición mas general será necesaria mas adelante. En esta definción en realidad estamos echando mano del hecho de que $(X_i-X_{i-1})^2 = 1$ para toda $i$ lo cual implica que la suma:
$$
\sum_{i=s+1}^t \left(X_{i} - X_{i-1}\right)^2  = t-s
$$
independientemente de la trayectoria. Si este no fuera el caso, entonces esta suma sería una variable aleatoria y la definición que propusimos sería insuficiente.  Por otro lado,  definimos la partición $\Pi = \{s, s+1, \ldots, t-1, t\}$ sobre el intervalo $[s,t]$ donde el proceso $\{X_t\}$ registra un salto en cada momento del tiempo $t\in \Pi$. En un modelo mas general, tendría sentido definir una partición del intervalo $[s, t]$ que fuera cada vez mas fina y calcular la variación cuadrática en ese contexto. Un paso en este sentido lo damos con la siguiente definición: 
\begin{definition}\thlabel{def:scaled_rw}
    Sea $\{X_n\}$ una caminata aleatoria simétrica. Definimos la \emph{caminata aleatoria escalada} $\{W^{(n)}_t\}$ como:
    \begin{equation}
        W^{(n)}_t = \frac{1}{\sqrt{n}} X_{nt} 
        \label{eq:scaled_rw}
    \end{equation}
\end{definition}
La caminata aleatoria escalada  ``acelera'' a la caminata aleatoria simétrica. Una caminata aleatoria simétrica registra un solo salto de tamaño 1 por unidad de tiempo. La caminata aleatoria escalada registra $n$ saltos por unidad de tiempo de tamaño $1/\sqrt{n}$. Por ejemplo, si $n= 100$ entonces cada salto de la caminata aleatoria escalada será de tamaño $1/10$. Al tiempo $t = 0.3$, la variable $W_{0.3}^{(100)}$ habrá registrado $0.3\times 100 = 30$ saltos de longitud $1/10$. Mientras que la diferencia $W^{(100)}_{0.7} - W^{(100)}_{0.2}$ registra los $(0.7-0.2)\times 100 = 30$ saltos que hay entre el tiempo $0.7$ y $0.2$ de longintud $1/\sqrt{10}$. En general la diferencia $W^{(n)}_t-W^{(n)}_t$, registra los $(t-s)\times n$ saltos de tamaño $1/\sqrt{n}$ que existen entre el tiempo $t$ y el tiempo $s$.
Observemos que:
\begin{equation*}
    \begin{split}
        E\left[W^{(n)}_t-W^{(n)}_s\right] & = E\left[\sum_{i= 1}^{n(t-s)}W_{s+i/n}^{(n)} - W_{s+(i-1)/n}^{(n)}\right]\\
                                     & = E\left[\frac{1}{\sqrt{n}}\sum_{i= 1}^{n(t-s)}Z_{s+i}\right]\\
                                     & = \frac{1}{\sqrt{n}}\sum_{i= 1}^{n(t-s)}E\left[Z_{s+i}\right]\\
                                     & = 0
    \end{split}
\end{equation*}
de manera análoga:
\begin{equation*}
    \begin{split}
        Var\left(W^{(n)}_t-W^{(n)}_s\right) & = Var\left(\sum_{i= 1}^{n(t-s)}W_{s+i/n}^{(n)} - W_{s+(i-1)/n}^{(n)}\right)\\
                                     & = Var\left(\frac{1}{\sqrt{n}}\sum_{i= 1}^{n(t-s)}Z_{s+i}\right)\\
                                     & = \frac{1}{n}\sum_{i= 1}^{n(t-s)}Var\left(Z_{s+i}\right)\\
                                     & = \frac{n(t-s)}{n}\\
                                     &= t-s
    \end{split}
\end{equation*}
Finalmente, la variación cuadrática sería
\begin{equation*}
    \begin{split}
        \left\langle W^{(n)}_t, W^{(n)}_t\right\rangle(t-s) & = \sum_{i= 1}^{n(t-s)}\left(W_{s+i/n}^{(n)} - W_{s+(i-1)/n}^{(n)}\right)^2\\
                                     & = \frac{1}{n}\sum_{i= 1}^{n(t-s)}Z_{s+i}^2\\
                                     & = \frac{1}{n}\sum_{i= 1}^{n(t-s)}1\\
                                     & = \frac{n(t-s)}{n}\\
                                     &= t-s
    \end{split}
\end{equation*}
El objetivo con la caminata aleatoria escalada, es hacer que $n\rightarrow\infty$, de modo que cada vez existan mas y mas saltos por unidad de tiempo.

Al tiempo $t$, la caminata aleatoria escalda $W_{t}^{(n)}$ habrá regristrado $nt$ saltos de logitud $1/\sqrt{n}$ de estos, $i$ podrían ser  “hacia arriba” y $nt-i$  “hacia abajo”. En tal caso:

$$
W_{t}^{(n)} =\frac{1}{\sqrt{n}}X_{nt} =  \frac{1}{\sqrt{n}}\sum_{i=1}^{nt}Z_i = \frac{1}{\sqrt{n}}\left(i-(nt-i)\right)= \frac{1}{\sqrt{n}}\left(2i-nt\right)
$$
para$i=0,1,\ldots, nt$. Notemos además que si $nt$  es par entonces $X_{nt}$  puede tomar cualquier valor par entre $-nt$ y $nt$. Del mismo modo, si $nt$ es impar $X_{nt}$ puede tomar cualquier valor impar entre $-nt$ y $nt$.

En cualquier caso:

\begin{align*}
P\left(W_{t}^{(n)} = \frac{1}{\sqrt{n}} (2i-nt)\right) & = P\left(X_{nt} =(2i-nt) \right)\\
                                                       &= \binom{nt}{i}\left(\frac{1}{2}\right)^i\left(\frac{1}{2}\right)^{nt-i}
\end{align*}


para $i=0,1,\ldots, nt$. La pregunta ahora es ¿Que pasa cuado $n\rightarrow\infty$?¿Que distribución tendrá la caminata aleatoria en el límite? Para responder esta pregunta consideremos la función generadora de momentos:
\begin{align*}
    E\left[e^{uW_{t}^{(n)}}\right] & = E\left[e^{u\frac{1}{\sqrt{n}}X_{nt}}\right]\\
                                   & = E\left[e^{u\frac{1}{\sqrt{n}}\sum_{i=1}^{nt}Z_i}\right]\\
\end{align*}
Como las variables aleatorias $Z_i$ son independientes: 
\begin{align*}
    E\left[e^{uW_{t}^{(n)}}\right] & = \prod_{i= 1}^{nt}E\left[e^{u\frac{1}{\sqrt{n}}Z}\right]\\
\end{align*}
donde $Z$ comparte distribución con las variables $\{Z_i\}$. Continuamos:
\begin{align*}
                                  \phi^{(n)}(u) & = E\left[e^{uW_{t}^{(n)}}\right] \\
                                   & = \prod_{i= 1}^{nt}E\left[e^{u\frac{1}{\sqrt{n}}Z}\right]\\
                                   & = \prod_{i=1}^{nt}\left(\frac{1}{2}e^{\frac{1}{\sqrt{n}}u} + \frac{1}{2}e^{-\frac{1}{\sqrt{n}}u}\right) \\
                                   & = \left(\frac{1}{2}e^{\frac{1}{\sqrt{n}}u} + \frac{1}{2}e^{-\frac{1}{\sqrt{n}}u}\right)^{nt} \\
\end{align*}
Por lo tanto buscamos:
$$
\lim_{n\rightarrow\infty}\phi^{(n)}(u) = \lim_{n\rightarrow\infty}\left(\frac{1}{2}e^{\frac{1}{\sqrt{n}}u} + \frac{1}{2}e^{-\frac{1}{\sqrt{n}}u}\right)^{nt}
$$
o mejor aun:
$$
\lim_{n\rightarrow\infty}\log\phi^{(n)}(u) = \lim_{n\rightarrow\infty}nt\log\left(\frac{1}{2}e^{\frac{1}{\sqrt{n}}u} + \frac{1}{2}e^{-\frac{1}{\sqrt{n}}u}\right)
$$
haciendo el cambio de variable $x = 1/\sqrt{n}$ buscamos el limite:
$$
\lim_{n\rightarrow\infty}\log\phi^{(n)}(u) = t\lim_{x\rightarrow 0}\frac{\log\left(\frac{1}{2}e^{ux} + \frac{1}{2}e^{-ux}\right)}{x^2}
$$
Usando L'Hôpital se sigue que:
$$
\lim_{n\rightarrow\infty}\log\phi^{(n)}(u) = \frac{t}{2}\lim_{x\rightarrow 0}\frac{\left(\frac{u}{2}e^{ux} - \frac{u}{2}e^{-ux}\right)}{x\left(\frac{1}{2}e^{ux} + \frac{1}{2}e^{-ux}\right)} = \frac{t}{2}\lim_{x\rightarrow 0}\frac{\left(\frac{u}{2}e^{ux} - \frac{u}{2}e^{-ux}\right)}{x}
$$
usando de nuevo L'Hôpital:
$$
\lim_{n\rightarrow\infty}\log\phi^{(n)}(u)  = \frac{t}{2}\lim_{x\rightarrow 0}\left(\frac{u^2}{2}e^{ux} + \frac{u^2}{2}e^{-ux}\right) = \frac{1}{2}u^2t
$$
por lo tanto
$$
\lim_{n\rightarrow\infty}\phi^{(n)}(u)  = e^{\frac{1}{2}u^2t}
$$
Esta última coincide con la función generadora de momentos de una variable aleatoria Normal con media cero y varianza $t$. Por lo tanto la distribución de $W_t^{(n)}$ converge a la distribución de una normal con media cero y varianza $t$ a medida que $n\rightarrow\infty$.
\newpage
\begin{definition}
    Dado un espacio de probabilidad filtrado $(\Omega,\mathcal{F}, P, \left\{F_t\right\})$ decimos que el proceso estocástico $W(t)$, $t\geq 0$ adaptado a la filtración es un \emph{Movimiento Browniano} si:
    \begin{enumerate}
        \item $W(0) = 0$
        \item Es de incrementos independientes
        \item $W(t)-W(s)$ se distribuye normal con media cero y varianza $t-s$.
    \end{enumerate}
\end{definition}
\end{document}

\section{Convergencia en probabilidad}

\subsection{Limites de conjuntos}

Dada una sucesión de variables aleatorias $\{X_i\}$ definimos los conjuntos:

$$
A_{i,\varepsilon}=\left\{\left|X_i-X\right\vert\leq\varepsilon\right\}
$$

para $\varepsilon>0$. Si $\omega \in A_{i,\varepsilon}$ entonces la distancia de $X_i$ a $X$ es menor que $\varepsilon$.  Si para algún $n$:

$$
\omega \in \bigcap_{i=n}^\infty A_{i,\varepsilon}
$$

entonces la distancia de $X_i$ a  $X$ es menor que $\varepsilon$ para toda $i\geq n$. Asimismo, si

$$
\omega \in \bigcup_{n=1}^{\infty}\bigcap_{i=n}^\infty A_{i,\varepsilon} = \liminf_{i\rightarrow \infty}A_{i,\varepsilon}
$$

$$
\inf A_i = \bigcap_{i=1}^\infty A_i \quad \text{y} \quad \sup A_i = \bigcup_{i=1}^\infty A_i \quad \text{y}
$$



\subsubsection{Limite de conjuntos}

Dada una colección de conjuntos $\{A_i\}$  decimos que:

$$
\inf_{k\geq n}A_k = \bigcap_{k=n}^\infty A_k \quad \text{y}\quad \sup_{k\geq n}A_k = \bigcup_{k=n}^\infty A_k
$$

Observemos que la sucesión  $\{\inf_{k\geq n} A_k\}_n$ es una sucesión creciente de conjuntos, mientras que la sucesión $\{\sup_{k\geq n}A_k\}_n$ es una sucesión decreciente.

Definimos además:

$$
\liminf_{k\rightarrow\infty} A_k = \bigcup_{n=1}^\infty\bigcap_{k=n}^\infty A_k\quad\text{y}\quad\limsup_{k\rightarrow\infty} A_k = \bigcap_{n=1}^\infty\bigcup_{k=n}^\infty A_k
$$

un resultado inmediato es el siguiente:

$$
\liminf_{k\rightarrow\infty}A_k \subset \limsup_{k\rightarrow\infty} A_k
$$

efectivamente; si $x\in \liminf_{k\rightarrow\infty}A_k$ entonces existe $n>0$ tal que $x\in A_k$  para todo $k>n$ por lo tanto $x\in \limsup_{k\rightarrow\infty}A_k$.

Si $\{A_i\}$  es una sucesión decreciente de conjuntos entonces:

$$
\lim_{i\rightarrow \infty}A_i = \bigcap_{i=1}^\infty A_i
$$

Como $\{A_i\}$ es decreciente, entonces:

$$
\bigcup_{k=n}^\infty A_k = A_n
$$

En consecuencia:

$$
\limsup_{k\rightarrow \infty} A_k = \bigcap_{n=1}^\infty\bigcup_{k=n}^\infty A_k = \bigcap_{n=1}^\infty A_n\subset \bigcup_{n=1}^\infty\bigcap_{k=n}^\infty A_k = \liminf_{k\rightarrow\infty}A_k
$$

lo cual demuestra el resultado.

Asimismo, si $\left\{A_i\right\}$ es una sucesión creciente de subconjuntos de $\Omega$ entonces:

$$
\lim_{i\rightarrow\infty}A_i = \bigcup_{i=1}^\infty A
$$

Dado que $\{A_i\}$ es creciente:

$$
\bigcap_{k=n}^\infty A_k= A_n 
$$

por lo tanto:

$$
\limsup_{k\rightarrow\infty}A_k = \bigcap_{n=1}^\infty\bigcup_{k=n}^\infty A_k \subset \bigcup_{n= 1}^\infty A_n = \bigcup_{n=1}^\infty\bigcap_{k=n}^\infty A_k = \liminf_{k\rightarrow\infty} A_k
$$

lo cual demuestra el resultado.



entonces podemos afirmar que para algún $n$ la distancia de $X_i$ a $X$ es menor que $\varepsilon$ para toda $i\geq n$. 

Dicho de otro modo si $\omega \in \liminf_{i\rightarrow \infty} A_{i,\varepsilon}$, para $\epsilon>0$ entonces existe alguna $n>0$ tal que$\left|X_i-X\right| \leq \epsilon$ para toda $i\geq n$. 

En este sentido decimos que $X_i$ converge en probabilidad a $X$  si para toda $\varepsilon>0$:

$$
P\left(\liminf_{i\rightarrow \infty}A_{i,\varepsilon}\right) = P\left(\bigcup_{n=1}^\infty\bigcap_{i=n}^\infty A_{i,\varepsilon}\right)= 1
$$

o bien si para todo $\epsilon > 0$

$$
P\left(\bigcap_{n=1}^\infty\bigcup_{i=n}^\infty A^c_{i,\varepsilon}\right) = P\left(\limsup_{i\rightarrow\infty}A^c_{i,\varepsilon}\right) = 0
$$

por otro lado, sabemos que:

$$
\limsup_{i\rightarrow\infty}A_i = \left\{\omega\in\Omega: \omega\in A_i, \quad i.o\right\}
$$

 además: 

$$
A^c_{i,\varepsilon}=\left\{\left|X_i-X\right\vert>\varepsilon\right\}
$$

por lo tanto $X_i$ converge en probabilidad a $X$ si:

$$
P\left(\left|X_i-X\right| >\varepsilon\quad i.o\right) = 0
$$

para todo $\varepsilon>0$.

De forma alternativa definimos los conjuntos:

$$
A_{i,m} = \left\{\vert X_i-X\vert \leq 1/m\right\}
$$

para alguna $m>0$. Si $\omega \in A_{i,m}$ entonces la distancia de $X_i$ a $X$ es menor que $1/m$. Asimismo, si para alguna  $n>0$

$$
\omega \in \bigcap_{i=n}^\infty A_{i,m}
$$

entonces, la distancia de $X_i$ a $X$ será menor que $1/m$ para toda $i\geq n$. De manera similar a como hicimos previamente, si 

$$
\omega \in \bigcup_{n=1}^\infty\bigcap_{i=n}^\infty A_{i,m} = \liminf_{i\rightarrow \infty} A_{i,m}
$$

entonces para alguna $n>0$ la distancia de $X_i$ a $X$ será menor a $1/m$ para toda $i\geq n$. 

Finalmente, si 

$$
\omega \in \bigcap_{m=1}^\infty\bigcup_{n=m}^\infty\bigcap_{i=n}^\infty A_{i,m} = \bigcap_{m=1}^\infty\liminf_{i\rightarrow \infty} A_{i,m} = \lim_{m\rightarrow\infty}\liminf_{i\rightarrow \infty} A_{i,m}
$$

entonces *para toda $m>0$ existe $n\geq m$ tal que $\vert X_i-X\vert < 1/m$ para toda $i\geq n$.* Por lo tanto si:

$$
P\left(\bigcap_{m=1}^\infty\bigcup_{n=m}^\infty\bigcap_{i=n}^\infty A_{i,m}\right) =\lim_{m\rightarrow\infty}P\left(\liminf_{i\rightarrow \infty} A_{i,m}\right) = 1
$$

entonces $X_i$ converge a $X$ en probabilidad. Esto mismo lo reescribimos usando complementos como:

$$
P\left(\bigcup_{m=1}^\infty\bigcap_{n=m}^\infty\bigcup_{i=n}^\infty A^c_{i,m}\right) =\lim_{m\rightarrow\infty}P\left(\limsup_{i\rightarrow \infty} A^c_{i,m}\right) = 0
$$

o bien

$$
\lim_{m\rightarrow\infty}P\left(\vert X_i-X\vert > 1/m \quad i.o\right) = 0
$$

