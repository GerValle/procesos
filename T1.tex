\documentclass{report}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{amssymb}
\setlength{\oddsidemargin}{0.5cm}
\setlength{\evensidemargin}{0.5cm}
\setlength{\textwidth}{15cm}
\setlength{\topmargin}{-2cm}

\begin{document}
\begin{center}
    \textsf{\Large Procesos Estocásticos}
    \par\medskip
    \textsf{\large Tarea 1}
\end{center}
\hrule
\par\bigskip
	Mas texto en rama alternativa

    Esto lo edite directo en origin/master?
	
Pongamos una linea adicional

De los problemas siguientes debes entrgar los problemas 2, 3, 11, 12, 14, 15, 16 y 18. Sin embargo es altamente recomendable que intentes resolverlos todos.
\begin{enumerate}
    \item Sea $X_n$ con $n\geq 0$ la cadena de Markov de dos estados. Encuentra:
          \begin{enumerate}
              \item $P\left(\left. x_1=0\right\vert X_0=0, X_2=0\right)$
              \item $P\left(X_1\neq X_2\right)$
          \end{enumerate}
    \item Supongamos que tenemos dos cajas con $2d$ bolas, de las cuales $d$ son negras y $d$ son rojas. Inicialmente $d$ bolas son colocadas en la caja 1 y el resto en la caja 2. En cada intento una bola es seleccionada de cada caja aleatoriamente y es cambiada de caja. Sea $X_0$ el número de bolas blancas que inicialmente se encuentran en la caja 1 y $X_n$ el número de bolas negras en la caja uno después de $n$ extracciones. Encuentra la probabilidad de transición de la cadena de Markov $\left\{X_n\right\}$.
    \item Sea $\left(\Omega, \mathcal{F}, P\right)$ un espacio de probabilidad. Si todos los conjuntos a continuación estan en $\mathcal{F}$, prueba:
          \begin{enumerate}
              \item Si $\left\{D_i\right\}$ es una sucesión de disjuntos, y $P(\left.C\right\vert D_i)=p$ entonces: $P\left(\left. C \right\vert \cup_i D_i\right)=p$.
              \item Si $\left\{C_i\right\}$ es una sucesión de disjuntos, entonces $P\left(\left.\cup C_i\right\vert D\right)= \sum P\left(\left.C_i\right\vert D\right)$.
              \item Si $\left\{E_i\right\}$ es una sucesión de disjuntos tales que $\cup E_i = \Omega$, entonces:
                    $$
                        P\left(\left.C\right\vert D \right)= \sum P\left(\left.E_i\right\vert D\right)P\left(\left. C\right\vert E_i\cap D\right).
                    $$
              \item Si $\left\{C_i\right\}$ es una sucesión de disjuntos y $P\left(\left. A\right\vert C_i\right) = P\left(\left. B\right\vert C_i\right)$ para todo $i$, entonces $P\left(\left. A\right\vert \cup C_i\right) = P\left(\left. B\right\vert \cup C_i\right)$
          \end{enumerate}
    \item Sea $\left\{X_n\right\}$ una cadana de Ehrenfest y Supongamos que $X_0$ tiene una distribución binomial con parámetros $n$ y $1/2$, es decir:
          $$
              P\left(X_0= x\right) = \binom{n}{x}\frac{1}{2^d}
          $$
          Encuentra la distribución de $X_1$.
    \item Demuestra que la cadena de Ehrenfest efectivamente cumple la propiedad de Markov.
    \item Demuestra que la caminata aleatoria es una cadena de Markov.
    \item Demuestra que la cadena de la ruina de jugador efectivamente es una cadena de Markov.
    \item Escribe la matriz de transición de la cadena de Ehrenfest si d = 7. Dibuja también la gráfica correspondiente.
    \item Escribe la matriz de transición para la cadena de la ruina del jugador si es que suponemos entre los dos jugadores hay \$7 en juego y la probabilidad de ganar del jugador 1 es de $p = 0.4$. Dibuja, también la gráfica de la matriz
    \item La cadena de Markov $\left\{X_n\right\}$ con estados 0, 1, 2 tiene la matriz de transición:
          $$P= \left[
                  \begin{matrix}
                      0.1 &  & 0.2 & 0.7 \\
                      0.9 &  & 0.1 & 0   \\
                      0.1 &  & 0.8 & 0.1 \\
                  \end{matrix}
                  \right]
          $$
          y distribución inicial $\pi_0= (0.3, 0.4, 0.3)$. Determina $P\left(X_0=0, X_1 = 1 X_2 = 2\right)$.
    \item La cadena de Markov $\left\{X_n\right\}$ con estados 0, 1, 2 tiene la matriz de transición:
          $$P= \left[
                  \begin{matrix}
                      0.1 &  & 0.1 & 0.8 \\
                      0.2 &  & 0.2 & 0.6 \\
                      0.3 &  & 0.3 & 0.4 \\
                  \end{matrix}
                  \right]
          $$
          Determina las probabilidades:
          $$P\left(\left. X_1=1, X_2 = 1 \right\vert  X_0 = 0\right) \textrm{ y } P\left(\left. X_2=1, X_3 = 1 \right\vert  X_1 = 0\right)$$.
          
    \item Un modelo simplificado de transmisión de enfermedades, funciona como sigue: El total de la población es $N=5$, de los cuales algunos estan enfermos y otros saludables. En cada periodo, son seleccionados dos individuos aleatoriamente e interactúan. Si un individuo se encuentra enfermo y el otro no, entonces el individuo saludable se enferma con probabilidad 0.1. En otro caso, no se da transmisión de la enfermedad. Sea $X_n$ el número de individuos enfermos al tiempo $n$. Determina la matriz de transición de este proceso.
    \item Sea $\left\{X_n\right\}$ una cadena de Markov con espacio de estados $S = \left\{1,2,3\right\}$ y matriz de transición:
          $$P= \left[
                  \begin{matrix}
                      0.6 &  & 0.3 & 0.1 \\
                      0.3 &  & 0.3 & 0.4 \\
                      0.4 &  & 0.1 & 0.5 \\
                  \end{matrix}
                  \right]
          $$
          
          Si se sabe que el proceso empieza en $X_0=1$, determina la probabilidad:
           $$P\left(X_0=1,X_1=0, X_2 = 2 \right)$$.
    \item Considera el problema de enviar un mensaje binario 0,1, a través de un canal de señales que consiste de varias estaciones, donde la transmisión a través de cada estación esta sujeta a una probabilidad fija $\alpha$ de error. Supongamos que $X_0=0$ y que $X_n$ es la señal recibida en la estación $n$.  Supongamos que $X_n$ es una cadena de Markov con probabilidades de transición $P(0,0) = P(1,1)= 1-\alpha$ y $P(0,1)=P(1,0)= \alpha$, con $0<\alpha<1$.
          \begin{enumerate}
              \item Determina la probabilidad $P\left(X_0=0,X_1=0, X_2=0\right)$
              \item Determina la probabilidad de que la señal recibida en la estacion 2 sea correcta.
          \end{enumerate}
    \item Las variables aleatorias $\xi_1, \xi_2, \ldots$ son independientes distribuidas:
          $$
              P\left(X_n=k\right)=
              \begin{cases}
                  0.1 \text{ si } k = 0 \\
                  0.3 \text{ si } k = 1 \\
                  0.2 \text{ si } k = 2 \\
                  0.4 \text{ si } k = 3
              \end{cases}
          $$
          Sea $X_0=0$, y sea $X_n= max\left\{\xi_1, \ldots,\xi_n\right\}$ el $\xi$ máximo observado hasta la fecha. Demuestra que $\left\{X_n\right\}$ es una cadena de Markov y determina la matriz de transición.
    \item Sea $\left\{X_n\right\}$ una cadena de Markov con espacio de estados $S = \left\{0,1,2\right\}$ y matriz de transición:
          $$P= \left[
                  \begin{matrix}
                      0.1 &  & 0.2 & 0.7 \\
                      0.2 &  & 0.2 & 0.6 \\
                      0.6 &  & 0.1 & 0.3 \\
                  \end{matrix}
                  \right]
          $$
          \begin{enumerate}
              \item Calcula la matriz de transición $P^{(2)}$ en dos pasos.
              \item Calcula: $P\left(\left. X_3 = 1\right\vert X_1=0\right)$
              \item Calcula: $P\left(\left. X_3 = 1\right\vert X_0=0\right)$
          \end{enumerate}
    \item Sea $\left\{X_n\right\}$ una cadena de Markov con matriz de transición:
          $$P= \left[
                  \begin{matrix}
                      0.6 &  & 0.3 & 0.1 \\
                      0.3 &  & 0.3 & 0.4 \\
                      0.4 &  & 0.1 & 0.5 \\
                  \end{matrix}
                  \right]
          $$
          Si se sabe que $X_0=1$, determina $P(X_2 = 1)$.
    \item Supongamos que $\left\{X_n\right\}$ es una cadena de Markov con dos estados y matriz de transición:
          $$P= \left[
                  \begin{matrix}
                      \alpha  & 1-\alpha \\
                      1-\beta & \beta    \\
                  \end{matrix}
                  \right]
          $$
          Demuestra que el proceso $\left\{Z_n\right\}= (X_{n-1}, X_n)$ con estados $(0,0)$, $(0,1)$, $(1,0)$, $(1,1)$, es una cadena de Markov. Determian su matriz de transición.
%    \item Sea $\left\{X_n\right\}$ una cadena de Markov. Muestra que
%          $$
%              P\left(\left.X_0=x_0\right\vert X_1 = x_1, \ldots, X_n = x_n\right) = P\left(\left. X_0=x_0 \right\vert X_1 %= x_1\right)
%          $$
%    \item Sea $\left\{X_n\right\}$ una cadena de Markov. Muestra que
%          $$
%              P\left(\left.X_{n+m}=x_{n+m}, \ldots, X_{n+1} = x_{n+1}\right\vert X_n = x_n\right) = P\left(\left.X_{m}=x_{n%+m}, \ldots, X_{1} = x_{n+1}\right\vert X_0 = x_n\right)
%          $$
          
\end{enumerate}
\end{document}